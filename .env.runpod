# RunPod GPU Environment Configuration

# Server Configuration
API_HOST=0.0.0.0
PORT=8000
WORKERS=4
API_PORT=8000
API_BASE_URL=http://localhost:8000

# Database Configuration (use internal service)
DATABASE_URL=
DATABASE_FORCE_IPV4=true
POSTGRES_PASSWORD=changeme

# Redis Configuration (use internal service)
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=changeme

# Authentication (GENERATE NEW SECRET!)
SECRET_KEY=CHANGE_THIS_RUN_openssl_rand_hex_32
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Storage Configuration
STORAGE_TYPE=local
STORAGE_PATH=/tmp/inference_storage
# For S3: STORAGE_TYPE=s3, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, S3_BUCKET

# Catalog admin
CATALOG_ADMIN_TOKEN=

# CORS (comma-separated origins or '*')
CORS_ALLOW_ORIGINS=*
CORS_ALLOW_CREDENTIALS=true

# Trust proxy headers (X-Forwarded-For) for rate limiting/client IP
TRUST_PROXY_HEADERS=false

# Webhook allowlist (comma-separated hostnames). Leave empty to allow all.
WEBHOOK_ALLOWED_HOSTS=

# Model Configuration
MODEL_CACHE_DIR=/tmp/model_cache
MAX_MODEL_CACHE_SIZE_GB=50

# Worker Configuration
CELERY_BROKER_URL=redis://:changeme@redis:6379/0
CELERY_RESULT_BACKEND=redis://:changeme@redis:6379/0
WORKER_CONCURRENCY=2

# GPU Configuration (ENABLED for RunPod)
ENABLE_GPU=true
DEFAULT_TIMEOUT=300
MAX_BATCH_SIZE=8

# CUDA Configuration
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
