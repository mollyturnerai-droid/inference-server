# Server Configuration
API_HOST=0.0.0.0
API_PORT=8000
WORKERS=4

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/inference_db

# Authentication
SECRET_KEY=your-secret-key-change-this
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Storage Configuration
STORAGE_TYPE=local
STORAGE_PATH=/tmp/inference_storage
# For S3: STORAGE_TYPE=s3, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, S3_BUCKET

# Model Configuration
MODEL_CACHE_DIR=/tmp/model_cache
MAX_MODEL_CACHE_SIZE_GB=50

# Worker Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
WORKER_CONCURRENCY=2

# Inference Configuration
DEFAULT_TIMEOUT=300
MAX_BATCH_SIZE=8
ENABLE_GPU=true
